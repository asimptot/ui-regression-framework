# ğŸ§ª Automated Regression Testing Framework

This project is a **headless browser-based visual regression testing** framework built using **Python**, **Selenium**, and **OpenCV**. It captures screenshots of test scenarios, compares them with baseline reference images, and generates a detailed HTML report with logs and image diffs.

---

## ğŸ“ Project Structure

```
project/
â”‚
â”œâ”€â”€ regression_test.py         # Main testing script
â”œâ”€â”€ init.py                    # Browser setup and helper methods
â”œâ”€â”€ Results/                   # Test result outputs
â”‚   â””â”€â”€ [PROD|TEST|ACC]/       # Environment-specific result folders
â”‚       â””â”€â”€ Reference/         # Reference images for comparison
```

---

## ğŸš€ Features

* âœ… **Automated Chrome testing** using `undetected-chromedriver` (headless mode)
* ğŸ–¼ï¸ **Screenshot-based comparison** using `SSIM` (Structural Similarity Index)
* ğŸ“Š **HTML Report Generation**:

  * Image comparison results
  * Load times
  * Browser console logs
  * Filtering by test status
* ğŸ§ª **Modular test case functions** (easily expandable)
* ğŸ§  **Automatic environment detection** from URL
* ğŸ§¹ **Cleans and organizes logs and screenshots**

---

## ğŸ› ï¸ Requirements

* Python 3.8+
* Chrome (v138 compatible with `undetected_chromedriver`)
* The following Python libraries:

```bash
pip install selenium undetected-chromedriver opencv-python scikit-image pillow
```

---

## ğŸ”§ Configuration

Modify the login section inside `init.py`:

```python
# init.py
WebDriverWait(self.browser, 20).until(
    EC.presence_of_element_located((By.ID, "YOUR ELEMENT ID"))
).send_keys('YOUR USERNAME')
...
```

Update the element selectors and credentials to match your application under test.

---

## ğŸ§ª Writing Tests

Test functions follow a common pattern:

1. Navigate and interact with UI elements
2. Take a screenshot
3. Store and compare with a reference
4. Log any browser console errors

Example test functions:

```python
def your_test_function1(self): ...
def your_test_function2(self): ...
```

---

## ğŸ–¼ï¸ Image Comparison

Uses **SSIM** to compare screenshots:

* If similarity is above threshold (`tolerance=0.999`), the test passes
* If not, a **diff image** is generated and included in the HTML report

You can crop regions of interest using `top_left` and `bottom_right` coordinates.

---

## ğŸ“„ HTML Report

The report includes:

* Total test summary (pass/fail)
* Execution duration
* Page load times
* Console logs
* Side-by-side image comparisons
* Dynamic filtering

Example:

```bash
Results/
â””â”€â”€ TEST/
    â””â”€â”€ 20250722_154501/
        â”œâ”€â”€ your_test_function1.png
        â”œâ”€â”€ your_test_function2.png
        â”œâ”€â”€ diff_your_test_function1.png
        â”œâ”€â”€ report_20250722_154501.html
```

---

## âœ… Running the Tests

Modify the `url` variable in `regression_test.py` to match your environment.

```python
if __name__ == "__main__":
    url = "https://your.testing.environment/"
```

Then run the script:

```bash
python regression_test.py
```

---

## ğŸ“Œ Notes

* Screenshots are saved in `Results/<ENV>/<timestamp>/`
* Reference images must exist in `Results/<ENV>/Reference/`
* The environment (`PROD`, `TEST`, `ACC`) is inferred from the URL
* Compatible with Windows-based paths and setups

---

## ğŸ§¼ Troubleshooting

* âŒ **Images Not Found?** â†’ Make sure the reference images are placed correctly.
* ğŸ–¼ **Images Not Aligned?** â†’ Adjust cropping coordinates in test comparison.
* ğŸ” **Login Fails?** â†’ Check element IDs and credentials in `init.py`.
* ğŸ§ª **SSIM < Tolerance?** â†’ Try loosening the `tolerance` if needed.

---

## ğŸ§© Extend the Framework

Add new test cases by:

1. Creating a function like `your_test_function3()`
2. Adding screenshot calls (`save_ss`)
3. Append to the `comparisons` list
4. Define a matching reference image

---

## ğŸ“¬ Contact

For questions or contributions, feel free to open an issue or submit a pull request.
